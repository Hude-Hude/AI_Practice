<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Structural Estimation for MDP</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="estimate_mdp_files/libs/clipboard/clipboard.min.js"></script>
<script src="estimate_mdp_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="estimate_mdp_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="estimate_mdp_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="estimate_mdp_files/libs/quarto-html/popper.min.js"></script>
<script src="estimate_mdp_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="estimate_mdp_files/libs/quarto-html/anchor.min.js"></script>
<link href="estimate_mdp_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="estimate_mdp_files/libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="estimate_mdp_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="estimate_mdp_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="estimate_mdp_files/libs/bootstrap/bootstrap-d6a003b94517c951b2d65075d42fb01b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#estimation-problem" id="toc-estimation-problem" class="nav-link active" data-scroll-target="#estimation-problem">Estimation Problem</a>
  <ul class="collapse">
  <li><a href="#objective" id="toc-objective" class="nav-link" data-scroll-target="#objective">Objective</a></li>
  <li><a href="#model-specification" id="toc-model-specification" class="nav-link" data-scroll-target="#model-specification">Model Specification</a></li>
  <li><a href="#choice-probability" id="toc-choice-probability" class="nav-link" data-scroll-target="#choice-probability">Choice Probability</a></li>
  </ul></li>
  <li><a href="#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#maximum-likelihood-estimation">Maximum Likelihood Estimation</a>
  <ul class="collapse">
  <li><a href="#likelihood-function" id="toc-likelihood-function" class="nav-link" data-scroll-target="#likelihood-function">Likelihood Function</a></li>
  <li><a href="#mle-estimator" id="toc-mle-estimator" class="nav-link" data-scroll-target="#mle-estimator">MLE Estimator</a></li>
  <li><a href="#computational-challenge" id="toc-computational-challenge" class="nav-link" data-scroll-target="#computational-challenge">Computational Challenge</a></li>
  </ul></li>
  <li><a href="#our-approach-nfxp-with-existing-solver" id="toc-our-approach-nfxp-with-existing-solver" class="nav-link" data-scroll-target="#our-approach-nfxp-with-existing-solver">Our Approach: NFXP with Existing Solver</a>
  <ul class="collapse">
  <li><a href="#key-insight" id="toc-key-insight" class="nav-link" data-scroll-target="#key-insight">Key Insight</a></li>
  <li><a href="#available-infrastructure" id="toc-available-infrastructure" class="nav-link" data-scroll-target="#available-infrastructure">Available Infrastructure</a></li>
  <li><a href="#algorithm-nfxp-nn-estimator" id="toc-algorithm-nfxp-nn-estimator" class="nav-link" data-scroll-target="#algorithm-nfxp-nn-estimator">Algorithm: NFXP-NN Estimator</a></li>
  <li><a href="#why-nelder-mead" id="toc-why-nelder-mead" class="nav-link" data-scroll-target="#why-nelder-mead">Why Nelder-Mead</a></li>
  <li><a href="#computational-cost" id="toc-computational-cost" class="nav-link" data-scroll-target="#computational-cost">Computational Cost</a></li>
  </ul></li>
  <li><a href="#identification" id="toc-identification" class="nav-link" data-scroll-target="#identification">Identification</a>
  <ul class="collapse">
  <li><a href="#identification-conditions" id="toc-identification-conditions" class="nav-link" data-scroll-target="#identification-conditions">Identification Conditions</a></li>
  <li><a href="#exclusion-restrictions" id="toc-exclusion-restrictions" class="nav-link" data-scroll-target="#exclusion-restrictions">Exclusion Restrictions</a></li>
  <li><a href="#special-case-direct-gamma-estimation" id="toc-special-case-direct-gamma-estimation" class="nav-link" data-scroll-target="#special-case-direct-gamma-estimation">Special Case: Direct <span class="math inline">\(\gamma\)</span> Estimation</a></li>
  </ul></li>
  <li><a href="#score-and-hessian" id="toc-score-and-hessian" class="nav-link" data-scroll-target="#score-and-hessian">Score and Hessian</a>
  <ul class="collapse">
  <li><a href="#score-function" id="toc-score-function" class="nav-link" data-scroll-target="#score-function">Score Function</a></li>
  <li><a href="#information-matrix" id="toc-information-matrix" class="nav-link" data-scroll-target="#information-matrix">Information Matrix</a></li>
  <li><a href="#asymptotic-distribution" id="toc-asymptotic-distribution" class="nav-link" data-scroll-target="#asymptotic-distribution">Asymptotic Distribution</a></li>
  <li><a href="#numerical-standard-errors" id="toc-numerical-standard-errors" class="nav-link" data-scroll-target="#numerical-standard-errors">Numerical Standard Errors</a></li>
  </ul></li>
  <li><a href="#alternative-approaches-for-reference" id="toc-alternative-approaches-for-reference" class="nav-link" data-scroll-target="#alternative-approaches-for-reference">Alternative Approaches (For Reference)</a>
  <ul class="collapse">
  <li><a href="#alternative-1-hotz-miller-ccp-inversion" id="toc-alternative-1-hotz-miller-ccp-inversion" class="nav-link" data-scroll-target="#alternative-1-hotz-miller-ccp-inversion">Alternative 1: Hotz-Miller CCP Inversion</a></li>
  <li><a href="#alternative-2-simulation-based-estimation-indirect-inference" id="toc-alternative-2-simulation-based-estimation-indirect-inference" class="nav-link" data-scroll-target="#alternative-2-simulation-based-estimation-indirect-inference">Alternative 2: Simulation-Based Estimation (Indirect Inference)</a></li>
  <li><a href="#alternative-3-bayesian-estimation" id="toc-alternative-3-bayesian-estimation" class="nav-link" data-scroll-target="#alternative-3-bayesian-estimation">Alternative 3: Bayesian Estimation</a></li>
  </ul></li>
  <li><a href="#summary-of-estimation-approaches" id="toc-summary-of-estimation-approaches" class="nav-link" data-scroll-target="#summary-of-estimation-approaches">Summary of Estimation Approaches</a></li>
  <li><a href="#implementation-roadmap" id="toc-implementation-roadmap" class="nav-link" data-scroll-target="#implementation-roadmap">Implementation Roadmap</a>
  <ul class="collapse">
  <li><a href="#module-structure" id="toc-module-structure" class="nav-link" data-scroll-target="#module-structure">Module Structure</a></li>
  <li><a href="#step-1-create-estimator-module" id="toc-step-1-create-estimator-module" class="nav-link" data-scroll-target="#step-1-create-estimator-module">Step 1: Create Estimator Module</a></li>
  <li><a href="#step-2-add-tests" id="toc-step-2-add-tests" class="nav-link" data-scroll-target="#step-2-add-tests">Step 2: Add Tests</a></li>
  <li><a href="#step-3-integration-in-quarto-report" id="toc-step-3-integration-in-quarto-report" class="nav-link" data-scroll-target="#step-3-integration-in-quarto-report">Step 3: Integration in Quarto Report</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Structural Estimation for MDP</h1>
<p class="subtitle lead">Parameter Recovery from Simulated Panel Data</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="estimation-problem" class="level2">
<h2 class="anchored" data-anchor-id="estimation-problem">Estimation Problem</h2>
<section id="objective" class="level3">
<h3 class="anchored" data-anchor-id="objective">Objective</h3>
<p>Given panel data <span class="math inline">\(\{(s_{it}, a_{it})\}_{i=1,\ldots,N; t=0,\ldots,T-1}\)</span> of states and actions, we seek to recover the structural parameters <span class="math inline">\(\theta = (\beta, \gamma, \delta)\)</span> that generated the data.</p>
</section>
<section id="model-specification" class="level3">
<h3 class="anchored" data-anchor-id="model-specification">Model Specification</h3>
<p>The data-generating process follows the dynamic discrete choice model:</p>
<ul>
<li><strong>State transition</strong>: <span class="math inline">\(s_{t+1} = (1 - \gamma) s_t + a_t\)</span> (deterministic)</li>
<li><strong>Flow reward</strong>: <span class="math inline">\(u(s, a) = \beta \log(1 + s) - a\)</span></li>
<li><strong>Choice-specific value function</strong>: <span class="math display">\[
v(s, a; \theta) = u(s, a) + \delta \bar{V}((1-\gamma)s + a; \theta)
\]</span></li>
<li><strong>Integrated value function</strong> (log-sum-exp): <span class="math display">\[
\bar{V}(s; \theta) = \log\left( \exp(v(s, 0; \theta)) + \exp(v(s, 1; \theta)) \right) + \gamma_E
\]</span> where <span class="math inline">\(\gamma_E \approx 0.5772\)</span> is Euler’s constant.</li>
</ul>
</section>
<section id="choice-probability" class="level3">
<h3 class="anchored" data-anchor-id="choice-probability">Choice Probability</h3>
<p>Under Type-I Extreme Value shocks, the probability of choosing action <span class="math inline">\(a = 1\)</span> given state <span class="math inline">\(s\)</span> is: <span class="math display">\[
P(a = 1 | s; \theta) = \frac{\exp(v(s, 1; \theta))}{\exp(v(s, 0; \theta)) + \exp(v(s, 1; \theta))} = \frac{1}{1 + \exp(v(s, 0; \theta) - v(s, 1; \theta))}
\]</span></p>
<p>This is the <strong>logit formula</strong> with choice probability determined by the value difference.</p>
</section>
</section>
<section id="maximum-likelihood-estimation" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimation">Maximum Likelihood Estimation</h2>
<section id="likelihood-function" class="level3">
<h3 class="anchored" data-anchor-id="likelihood-function">Likelihood Function</h3>
<p>The log-likelihood of observing the panel data is: <span class="math display">\[
\mathcal{L}(\theta) = \sum_{i=1}^{N} \sum_{t=0}^{T-1} \log P(a_{it} | s_{it}; \theta)
\]</span></p>
<p>Expanding the choice probability: <span class="math display">\[
\mathcal{L}(\theta) = \sum_{i=1}^{N} \sum_{t=0}^{T-1} \left[ a_{it} \cdot v(s_{it}, 1; \theta) + (1 - a_{it}) \cdot v(s_{it}, 0; \theta) - \log\left( \exp(v(s_{it}, 0; \theta)) + \exp(v(s_{it}, 1; \theta)) \right) \right]
\]</span></p>
<p>Or equivalently: <span class="math display">\[
\mathcal{L}(\theta) = \sum_{i=1}^{N} \sum_{t=0}^{T-1} \left[ a_{it} \cdot \Delta v(s_{it}; \theta) - \log\left( 1 + \exp(\Delta v(s_{it}; \theta)) \right) \right]
\]</span> where <span class="math inline">\(\Delta v(s; \theta) = v(s, 1; \theta) - v(s, 0; \theta)\)</span> is the value difference.</p>
</section>
<section id="mle-estimator" class="level3">
<h3 class="anchored" data-anchor-id="mle-estimator">MLE Estimator</h3>
<p>The maximum likelihood estimator is: <span class="math display">\[
\hat{\theta}_{MLE} = \arg\max_{\theta} \mathcal{L}(\theta)
\]</span></p>
</section>
<section id="computational-challenge" class="level3">
<h3 class="anchored" data-anchor-id="computational-challenge">Computational Challenge</h3>
<p>The key challenge is that evaluating <span class="math inline">\(\mathcal{L}(\theta)\)</span> requires computing the value functions <span class="math inline">\(v(s, a; \theta)\)</span>, which themselves depend on <span class="math inline">\(\theta\)</span> through the Bellman equation. This creates a <strong>nested optimization problem</strong>.</p>
</section>
</section>
<section id="our-approach-nfxp-with-existing-solver" class="level2">
<h2 class="anchored" data-anchor-id="our-approach-nfxp-with-existing-solver">Our Approach: NFXP with Existing Solver</h2>
<section id="key-insight" class="level3">
<h3 class="anchored" data-anchor-id="key-insight">Key Insight</h3>
<p>We have already implemented a neural network-based value function solver in <code>mdp_solver</code>. This solver can be directly invoked for any candidate parameters <span class="math inline">\(\theta = (\beta, \gamma, \delta)\)</span>. The estimation problem becomes straightforward:</p>
<ul>
<li><strong>Inner loop</strong>: Call our existing <code>solve_value_function(beta, gamma, delta, ...)</code> to obtain converged value networks</li>
<li><strong>Outer loop</strong>: Use the value networks to compute choice probabilities and optimize the likelihood</li>
</ul>
</section>
<section id="available-infrastructure" class="level3">
<h3 class="anchored" data-anchor-id="available-infrastructure">Available Infrastructure</h3>
<p>From <code>src/mdp_solver</code>, we have:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 52%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th>Function</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>solve_value_function(beta, gamma, delta, ...)</code></td>
<td>Solves Bellman iteration for given parameters</td>
</tr>
<tr class="even">
<td><code>compute_choice_probability(v0_net, v1_net, s)</code></td>
<td>Computes <span class="math inline">\(P(a=1|s)\)</span> from value networks</td>
</tr>
<tr class="odd">
<td><code>build_monotonic_network(hidden_sizes)</code></td>
<td>Creates network architecture</td>
</tr>
<tr class="even">
<td><code>evaluate_network(net, s)</code></td>
<td>Evaluates value function at states</td>
</tr>
</tbody>
</table>
</section>
<section id="algorithm-nfxp-nn-estimator" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-nfxp-nn-estimator">Algorithm: NFXP-NN Estimator</h3>
<p>We use derivative-free optimization (Nelder-Mead) for the outer loop, which is well-suited for our 3-parameter problem. The optimizer evaluates the negative log-likelihood at candidate parameter values, where each evaluation requires solving the full dynamic programming problem.</p>
<section id="pseudocode-main-estimation-routine" class="level4">
<h4 class="anchored" data-anchor-id="pseudocode-main-estimation-routine">Pseudocode: Main Estimation Routine</h4>
<pre><code>FUNCTION ESTIMATE_MLE(data, theta_init, solver_params, bounds):
    """
    Estimate structural parameters via Maximum Likelihood.
    
    Inputs:
        data: PanelData object containing:
            - states: np.ndarray of shape (n_agents, n_periods)
            - actions: np.ndarray of shape (n_agents, n_periods)
        theta_init: tuple (beta_init, gamma_init, delta_init)
        solver_params: dict containing:
            - s_min: float, minimum state value
            - s_max: float, maximum state value
            - hidden_sizes: list[int], network architecture
            - learning_rate: float
            - batch_size: int
            - tolerance: float, convergence tolerance for inner loop
            - max_iterations: int, max iterations for inner loop
            - target_update_freq: int
        bounds: list of tuples [(beta_lo, beta_hi), (gamma_lo, gamma_hi), (delta_lo, delta_hi)]
    
    Outputs:
        theta_hat: tuple (beta_hat, gamma_hat, delta_hat)
        result: scipy.optimize.OptimizeResult object
    """
    
    # Define objective function (negative log-likelihood)
    FUNCTION neg_log_likelihood(theta):
        log_lik = COMPUTE_LOG_LIKELIHOOD(theta, data, solver_params)
        RETURN -log_lik
    
    # Run Nelder-Mead optimization
    result = scipy.optimize.minimize(
        fun=neg_log_likelihood,
        x0=theta_init,
        method='Nelder-Mead',
        options={
            'maxiter': 200,
            'xatol': 1e-4,      # Parameter tolerance
            'fatol': 1e-4,      # Function value tolerance
            'disp': True,
            'adaptive': True    # Adapt simplex to parameter scales
        }
    )
    
    theta_hat = result.x
    RETURN theta_hat, result</code></pre>
</section>
<section id="pseudocode-log-likelihood-computation-inner-loop" class="level4">
<h4 class="anchored" data-anchor-id="pseudocode-log-likelihood-computation-inner-loop">Pseudocode: Log-Likelihood Computation (Inner Loop)</h4>
<pre><code>FUNCTION COMPUTE_LOG_LIKELIHOOD(theta, data, solver_params):
    """
    Compute log-likelihood for candidate parameters.
    This is called once per outer loop iteration.
    
    Inputs:
        theta: tuple (beta, gamma, delta)
        data: PanelData object
        solver_params: dict with solver hyperparameters
    
    Outputs:
        log_lik: float, total log-likelihood
    """
    
    # Unpack parameters
    beta, gamma, delta = theta
    
    # Validate parameter bounds (return -inf for invalid)
    IF beta &lt;= 0 OR gamma &lt;= 0 OR gamma &gt;= 1 OR delta &lt;= 0 OR delta &gt;= 1:
        RETURN -np.inf
    
    # === INNER LOOP: Solve value functions for this theta ===
    v0_net, v1_net, losses, n_iter = solve_value_function(
        beta=beta,
        gamma=gamma,
        delta=delta,
        s_min=solver_params['s_min'],
        s_max=solver_params['s_max'],
        hidden_sizes=solver_params['hidden_sizes'],
        learning_rate=solver_params['learning_rate'],
        batch_size=solver_params['batch_size'],
        tolerance=solver_params['tolerance'],
        max_iterations=solver_params['max_iterations'],
        target_update_freq=solver_params['target_update_freq']
    )
    
    # Check convergence (optional: warn if not converged)
    IF n_iter == solver_params['max_iterations']:
        PRINT warning: "Inner loop did not converge for theta =", theta
    
    # === Compute choice probabilities at all observed states ===
    # Flatten panel data for batch computation
    states_flat = data.states.flatten()  # shape: (N * T,)
    actions_flat = data.actions.flatten()  # shape: (N * T,)
    
    # Convert to tensor
    s_tensor = torch.tensor(states_flat, dtype=torch.float32)
    
    # Compute P(a=1 | s) for all observations
    WITH torch.no_grad():
        p1 = compute_choice_probability(v0_net, v1_net, s_tensor)
        p1 = p1.numpy()
    
    # Clip probabilities for numerical stability
    eps = 1e-10
    p1 = np.clip(p1, eps, 1 - eps)
    
    # === Compute log-likelihood ===
    # L = Σ [a * log(p1) + (1-a) * log(1-p1)]
    log_lik = np.sum(
        actions_flat * np.log(p1) + 
        (1 - actions_flat) * np.log(1 - p1)
    )
    
    RETURN log_lik</code></pre>
</section>
<section id="pseudocode-standard-error-computation" class="level4">
<h4 class="anchored" data-anchor-id="pseudocode-standard-error-computation">Pseudocode: Standard Error Computation</h4>
<pre><code>FUNCTION COMPUTE_STANDARD_ERRORS(theta_hat, data, solver_params, eps=1e-4):
    """
    Compute standard errors via numerical Hessian at the MLE.
    
    Inputs:
        theta_hat: tuple (beta_hat, gamma_hat, delta_hat), MLE estimates
        data: PanelData object
        solver_params: dict
        eps: float, step size for finite differences
    
    Outputs:
        std_errors: np.ndarray of shape (3,)
        cov_matrix: np.ndarray of shape (3, 3)
    """
    
    n_params = 3
    theta_hat = np.array(theta_hat)
    
    # Compute numerical Hessian via central differences
    hessian = np.zeros((n_params, n_params))
    
    FOR i IN range(n_params):
        FOR j IN range(n_params):
            # f(θ + ei*eps + ej*eps)
            theta_pp = theta_hat.copy()
            theta_pp[i] += eps
            theta_pp[j] += eps
            f_pp = COMPUTE_LOG_LIKELIHOOD(theta_pp, data, solver_params)
            
            # f(θ + ei*eps - ej*eps)
            theta_pm = theta_hat.copy()
            theta_pm[i] += eps
            theta_pm[j] -= eps
            f_pm = COMPUTE_LOG_LIKELIHOOD(theta_pm, data, solver_params)
            
            # f(θ - ei*eps + ej*eps)
            theta_mp = theta_hat.copy()
            theta_mp[i] -= eps
            theta_mp[j] += eps
            f_mp = COMPUTE_LOG_LIKELIHOOD(theta_mp, data, solver_params)
            
            # f(θ - ei*eps - ej*eps)
            theta_mm = theta_hat.copy()
            theta_mm[i] -= eps
            theta_mm[j] -= eps
            f_mm = COMPUTE_LOG_LIKELIHOOD(theta_mm, data, solver_params)
            
            # Second derivative approximation
            hessian[i, j] = (f_pp - f_pm - f_mp + f_mm) / (4 * eps * eps)
    
    # Covariance matrix = inverse of negative Hessian (information matrix)
    info_matrix = -hessian
    cov_matrix = np.linalg.inv(info_matrix)
    
    # Standard errors = sqrt of diagonal
    std_errors = np.sqrt(np.diag(cov_matrix))
    
    RETURN std_errors, cov_matrix</code></pre>
</section>
</section>
<section id="why-nelder-mead" class="level3">
<h3 class="anchored" data-anchor-id="why-nelder-mead">Why Nelder-Mead</h3>
<p>For our 3-parameter problem, Nelder-Mead is the practical choice:</p>
<ol type="1">
<li><p><strong>No gradients required</strong>: Computing <span class="math inline">\(\partial \mathcal{L}/\partial \theta\)</span> would require differentiating through thousands of inner loop iterations — complex and numerically unstable.</p></li>
<li><p><strong>Robust</strong>: Nelder-Mead handles non-smooth objective functions and doesn’t get stuck on saddle points.</p></li>
<li><p><strong>Sufficient for low dimensions</strong>: With only 3 parameters, Nelder-Mead converges in reasonable time (~50-200 function evaluations).</p></li>
<li><p><strong>Each evaluation is expensive</strong>: Our inner loop (solving the DP) dominates computation time. Nelder-Mead minimizes the number of evaluations.</p></li>
</ol>
</section>
<section id="computational-cost" class="level3">
<h3 class="anchored" data-anchor-id="computational-cost">Computational Cost</h3>
<p>Each outer loop iteration requires: - 1 call to <code>solve_value_function</code> (inner loop): ~1000-10000 iterations of neural network training - 1 batch evaluation of choice probabilities: O(N × T) forward passes</p>
<p>Total estimation: ~50-200 outer iterations × inner loop cost</p>
</section>
</section>
<section id="identification" class="level2">
<h2 class="anchored" data-anchor-id="identification">Identification</h2>
<section id="identification-conditions" class="level3">
<h3 class="anchored" data-anchor-id="identification-conditions">Identification Conditions</h3>
<p>For the parameters <span class="math inline">\((\beta, \gamma, \delta)\)</span> to be identified from choice data:</p>
<ol type="1">
<li><p><strong>Reward normalization</strong>: One parameter must be normalized. Typically, the coefficient on the action cost is set to 1, so the reward is <span class="math inline">\(u(s,a) = \beta \log(1+s) - a\)</span> (the <span class="math inline">\(-a\)</span> term is normalized to have coefficient -1).</p></li>
<li><p><strong>Variation in states</strong>: The data must contain sufficient variation in states <span class="math inline">\(s\)</span> to identify <span class="math inline">\(\beta\)</span> from the state-dependent reward component <span class="math inline">\(\beta \log(1+s)\)</span>.</p></li>
<li><p><strong>Discount factor</strong>: <span class="math inline">\(\delta\)</span> is identified from the forward-looking behavior. Higher <span class="math inline">\(\delta\)</span> means agents put more weight on future states, affecting current choices.</p></li>
<li><p><strong>Transition parameter</strong>: <span class="math inline">\(\gamma\)</span> is directly identified from observed state transitions: <span class="math display">\[
\gamma = 1 - \frac{s_{t+1} - a_t}{s_t} \quad \text{(when } s_t \neq 0 \text{)}
\]</span></p></li>
</ol>
</section>
<section id="exclusion-restrictions" class="level3">
<h3 class="anchored" data-anchor-id="exclusion-restrictions">Exclusion Restrictions</h3>
<p>In our model: - <span class="math inline">\(\gamma\)</span> enters only the transition equation, not the flow reward - <span class="math inline">\(\beta\)</span> enters only the flow reward, not the transition - <span class="math inline">\(\delta\)</span> appears only in the discounting of future values</p>
<p>This separation aids identification.</p>
</section>
<section id="special-case-direct-gamma-estimation" class="level3">
<h3 class="anchored" data-anchor-id="special-case-direct-gamma-estimation">Special Case: Direct <span class="math inline">\(\gamma\)</span> Estimation</h3>
<p>Since state transitions are deterministic, <span class="math inline">\(\gamma\)</span> can be estimated directly from observed transitions without solving the DP problem: <span class="math display">\[
\hat{\gamma} = 1 - \frac{1}{|\mathcal{D}|} \sum_{(s_t, a_t, s_{t+1}) \in \mathcal{D}} \frac{s_{t+1} - a_t}{s_t}
\]</span></p>
<p>This reduces the estimation problem to finding <span class="math inline">\((\beta, \delta)\)</span> given known <span class="math inline">\(\gamma\)</span>.</p>
</section>
</section>
<section id="score-and-hessian" class="level2">
<h2 class="anchored" data-anchor-id="score-and-hessian">Score and Hessian</h2>
<section id="score-function" class="level3">
<h3 class="anchored" data-anchor-id="score-function">Score Function</h3>
<p>The score (gradient of log-likelihood) with respect to <span class="math inline">\(\theta\)</span> is: <span class="math display">\[
S(\theta) = \frac{\partial \mathcal{L}}{\partial \theta} = \sum_{i,t} \left( a_{it} - P(a=1|s_{it}; \theta) \right) \cdot \frac{\partial \Delta v(s_{it}; \theta)}{\partial \theta}
\]</span></p>
<p>This has the intuitive form: prediction error <span class="math inline">\(\times\)</span> sensitivity of value difference to parameters.</p>
</section>
<section id="information-matrix" class="level3">
<h3 class="anchored" data-anchor-id="information-matrix">Information Matrix</h3>
<p>The expected (Fisher) information matrix is: <span class="math display">\[
\mathcal{I}(\theta) = -\mathbb{E}\left[ \frac{\partial^2 \mathcal{L}}{\partial \theta \partial \theta'} \right] = \sum_{i,t} P(1-P) \cdot \frac{\partial \Delta v}{\partial \theta} \cdot \frac{\partial \Delta v}{\partial \theta'}
\]</span> where <span class="math inline">\(P = P(a=1|s_{it}; \theta)\)</span>.</p>
</section>
<section id="asymptotic-distribution" class="level3">
<h3 class="anchored" data-anchor-id="asymptotic-distribution">Asymptotic Distribution</h3>
<p>Under regularity conditions, the MLE is asymptotically normal: <span class="math display">\[
\sqrt{NT}(\hat{\theta} - \theta_0) \xrightarrow{d} \mathcal{N}(0, \mathcal{I}(\theta_0)^{-1})
\]</span></p>
<p>Standard errors can be computed from the inverse of the estimated information matrix.</p>
</section>
<section id="numerical-standard-errors" class="level3">
<h3 class="anchored" data-anchor-id="numerical-standard-errors">Numerical Standard Errors</h3>
<p>For derivative-free optimization, standard errors can be computed via: 1. <strong>Numerical Hessian</strong>: Finite differences around <span class="math inline">\(\hat{\theta}\)</span> 2. <strong>Bootstrap</strong>: Resample the panel data and re-estimate 3. <strong>Outer product of gradients (OPG)</strong>: If numerical gradients are available</p>
</section>
</section>
<section id="alternative-approaches-for-reference" class="level2">
<h2 class="anchored" data-anchor-id="alternative-approaches-for-reference">Alternative Approaches (For Reference)</h2>
<section id="alternative-1-hotz-miller-ccp-inversion" class="level3">
<h3 class="anchored" data-anchor-id="alternative-1-hotz-miller-ccp-inversion">Alternative 1: Hotz-Miller CCP Inversion</h3>
<p>Instead of solving the full dynamic problem, Hotz and Miller (1993) showed that value differences can be expressed in terms of observable CCPs: <span class="math display">\[
v(s, 1) - v(s, 0) = \log\left( \frac{P(a=1|s)}{P(a=0|s)} \right)
\]</span></p>
<p><strong>Two-Step Estimation</strong>:</p>
<ol type="1">
<li><p><strong>First stage</strong>: Estimate CCPs non-parametrically from the data: <span class="math display">\[
\hat{P}(a=1|s) = \frac{\sum_{i,t} \mathbf{1}[a_{it}=1, s_{it} \approx s]}{\sum_{i,t} \mathbf{1}[s_{it} \approx s]}
\]</span></p></li>
<li><p><strong>Second stage</strong>: Use the inverted CCPs to form moment conditions and estimate structural parameters.</p></li>
</ol>
<p><strong>Pros</strong>: Avoids solving the Bellman equation repeatedly <strong>Cons</strong>: Requires accurate first-stage CCP estimates, which introduces noise — particularly problematic with limited data or sparse state coverage</p>
</section>
<section id="alternative-2-simulation-based-estimation-indirect-inference" class="level3">
<h3 class="anchored" data-anchor-id="alternative-2-simulation-based-estimation-indirect-inference">Alternative 2: Simulation-Based Estimation (Indirect Inference)</h3>
<p>Simulate data from the model at candidate parameters and match moments: <span class="math display">\[
\hat{\theta} = \arg\min_{\theta} \left( m(\text{data}) - m(\text{simulated}(\theta)) \right)' W \left( m(\text{data}) - m(\text{simulated}(\theta)) \right)
\]</span></p>
<p><strong>Pros</strong>: Flexible, can match any computable moments <strong>Cons</strong>: Requires many simulations, choice of moments affects efficiency</p>
</section>
<section id="alternative-3-bayesian-estimation" class="level3">
<h3 class="anchored" data-anchor-id="alternative-3-bayesian-estimation">Alternative 3: Bayesian Estimation</h3>
<p>Place priors on <span class="math inline">\(\theta\)</span> and compute posterior: <span class="math display">\[
p(\theta | \text{data}) \propto \mathcal{L}(\theta) \cdot p(\theta)
\]</span></p>
<p><strong>Pros</strong>: Quantifies parameter uncertainty, regularizes estimation <strong>Cons</strong>: Computationally intensive (MCMC), requires prior specification</p>
</section>
</section>
<section id="summary-of-estimation-approaches" class="level2">
<h2 class="anchored" data-anchor-id="summary-of-estimation-approaches">Summary of Estimation Approaches</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 45%">
<col style="width: 27%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>NFXP-NN (Our Approach)</strong></td>
<td>Reuses existing solver, exact probabilities, no CCP noise</td>
<td>Requires solving DP per evaluation</td>
</tr>
<tr class="even">
<td><strong>Hotz-Miller CCP</strong></td>
<td>Avoids repeated DP</td>
<td>Noisy CCP estimates, binning artifacts</td>
</tr>
<tr class="odd">
<td><strong>Indirect Inference</strong></td>
<td>Flexible moment matching</td>
<td>Many simulations needed</td>
</tr>
<tr class="even">
<td><strong>Bayesian</strong></td>
<td>Full uncertainty quantification</td>
<td>MCMC computational cost</td>
</tr>
</tbody>
</table>
</section>
<section id="implementation-roadmap" class="level2">
<h2 class="anchored" data-anchor-id="implementation-roadmap">Implementation Roadmap</h2>
<section id="module-structure" class="level3">
<h3 class="anchored" data-anchor-id="module-structure">Module Structure</h3>
<pre><code>src/mdp_estimator/
├── __init__.py
├── mdp_estimator.py      # Core estimation functions
└── utils.py              # Helper functions (numerical Hessian, etc.)

test/mdp_estimator/
└── test_estimator.py     # Unit and integration tests</code></pre>
</section>
<section id="step-1-create-estimator-module" class="level3">
<h3 class="anchored" data-anchor-id="step-1-create-estimator-module">Step 1: Create Estimator Module</h3>
<p>File: <code>src/mdp_estimator/mdp_estimator.py</code></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">"""MDP Structural Parameter Estimator using NFXP."""</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> optimize</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dataclasses <span class="im">import</span> dataclass</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Tuple, Dict, Any, Optional</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mdp_solver <span class="im">import</span> solve_value_function, compute_choice_probability</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mdp_simulator <span class="im">import</span> PanelData</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EstimationResult:</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Container for estimation results."""</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    theta_hat: np.ndarray          <span class="co"># (beta, gamma, delta)</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    std_errors: np.ndarray         <span class="co"># Standard errors</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    cov_matrix: np.ndarray         <span class="co"># Covariance matrix</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    log_likelihood: <span class="bu">float</span>          <span class="co"># Log-likelihood at optimum</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    n_iterations: <span class="bu">int</span>              <span class="co"># Outer loop iterations</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    converged: <span class="bu">bool</span>                <span class="co"># Whether optimizer converged</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    optimization_result: Any       <span class="co"># Full scipy result object</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_log_likelihood(</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    theta: np.ndarray,</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    data: PanelData,</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    solver_params: Dict[<span class="bu">str</span>, Any],</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute log-likelihood for candidate parameters.</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a><span class="co">    theta : np.ndarray</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters (beta, gamma, delta)</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a><span class="co">    data : PanelData</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a><span class="co">        Panel data with states and actions</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a><span class="co">    solver_params : dict</span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="co">        Solver hyperparameters (s_min, s_max, hidden_sizes, etc.)</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="co">    float</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a><span class="co">        Log-likelihood value</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    beta, gamma, delta <span class="op">=</span> theta</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validate bounds</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> beta <span class="op">&lt;=</span> <span class="dv">0</span> <span class="kw">or</span> gamma <span class="op">&lt;=</span> <span class="dv">0</span> <span class="kw">or</span> gamma <span class="op">&gt;=</span> <span class="dv">1</span> <span class="kw">or</span> delta <span class="op">&lt;=</span> <span class="dv">0</span> <span class="kw">or</span> delta <span class="op">&gt;=</span> <span class="dv">1</span>:</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span>np.inf</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inner loop: solve for value functions</span></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>    v0_net, v1_net, losses, n_iter <span class="op">=</span> solve_value_function(</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>        beta<span class="op">=</span>beta,</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        gamma<span class="op">=</span>gamma,</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>        delta<span class="op">=</span>delta,</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>        s_min<span class="op">=</span>solver_params[<span class="st">'s_min'</span>],</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>        s_max<span class="op">=</span>solver_params[<span class="st">'s_max'</span>],</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>        hidden_sizes<span class="op">=</span>solver_params[<span class="st">'hidden_sizes'</span>],</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>        learning_rate<span class="op">=</span>solver_params[<span class="st">'learning_rate'</span>],</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span>solver_params[<span class="st">'batch_size'</span>],</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>        tolerance<span class="op">=</span>solver_params[<span class="st">'tolerance'</span>],</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>        max_iterations<span class="op">=</span>solver_params[<span class="st">'max_iterations'</span>],</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>        target_update_freq<span class="op">=</span>solver_params.get(<span class="st">'target_update_freq'</span>, <span class="dv">100</span>),</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute choice probabilities</span></span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>    states_flat <span class="op">=</span> data.states.flatten()</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>    actions_flat <span class="op">=</span> data.actions.flatten()</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>    s_tensor <span class="op">=</span> torch.tensor(states_flat, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>        p1 <span class="op">=</span> compute_choice_probability(v0_net, v1_net, s_tensor).numpy()</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Clip for numerical stability</span></span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>    eps <span class="op">=</span> <span class="fl">1e-10</span></span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>    p1 <span class="op">=</span> np.clip(p1, eps, <span class="dv">1</span> <span class="op">-</span> eps)</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log-likelihood</span></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>    log_lik <span class="op">=</span> np.<span class="bu">sum</span>(</span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>        actions_flat <span class="op">*</span> np.log(p1) <span class="op">+</span> </span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>        (<span class="dv">1</span> <span class="op">-</span> actions_flat) <span class="op">*</span> np.log(<span class="dv">1</span> <span class="op">-</span> p1)</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> log_lik</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> estimate_mle(</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>    data: PanelData,</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>    theta_init: Tuple[<span class="bu">float</span>, <span class="bu">float</span>, <span class="bu">float</span>],</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a>    solver_params: Dict[<span class="bu">str</span>, Any],</span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>    maxiter: <span class="bu">int</span> <span class="op">=</span> <span class="dv">200</span>,</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>    verbose: <span class="bu">bool</span> <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> EstimationResult:</span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a><span class="co">    Estimate structural parameters via MLE using NFXP.</span></span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a><span class="co">    data : PanelData</span></span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a><span class="co">        Panel data with states and actions</span></span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a><span class="co">    theta_init : tuple</span></span>
<span id="cb5-104"><a href="#cb5-104" aria-hidden="true" tabindex="-1"></a><span class="co">        Initial guess (beta, gamma, delta)</span></span>
<span id="cb5-105"><a href="#cb5-105" aria-hidden="true" tabindex="-1"></a><span class="co">    solver_params : dict</span></span>
<span id="cb5-106"><a href="#cb5-106" aria-hidden="true" tabindex="-1"></a><span class="co">        Solver hyperparameters</span></span>
<span id="cb5-107"><a href="#cb5-107" aria-hidden="true" tabindex="-1"></a><span class="co">    maxiter : int</span></span>
<span id="cb5-108"><a href="#cb5-108" aria-hidden="true" tabindex="-1"></a><span class="co">        Maximum outer loop iterations</span></span>
<span id="cb5-109"><a href="#cb5-109" aria-hidden="true" tabindex="-1"></a><span class="co">    verbose : bool</span></span>
<span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a><span class="co">        Print progress</span></span>
<span id="cb5-111"><a href="#cb5-111" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb5-112"><a href="#cb5-112" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb5-113"><a href="#cb5-113" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb5-114"><a href="#cb5-114" aria-hidden="true" tabindex="-1"></a><span class="co">    EstimationResult</span></span>
<span id="cb5-115"><a href="#cb5-115" aria-hidden="true" tabindex="-1"></a><span class="co">        Estimation results including estimates and standard errors</span></span>
<span id="cb5-116"><a href="#cb5-116" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-117"><a href="#cb5-117" aria-hidden="true" tabindex="-1"></a>    theta_init <span class="op">=</span> np.array(theta_init)</span>
<span id="cb5-118"><a href="#cb5-118" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-119"><a href="#cb5-119" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Track evaluations</span></span>
<span id="cb5-120"><a href="#cb5-120" aria-hidden="true" tabindex="-1"></a>    eval_count <span class="op">=</span> [<span class="dv">0</span>]</span>
<span id="cb5-121"><a href="#cb5-121" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-122"><a href="#cb5-122" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> neg_log_lik(theta):</span>
<span id="cb5-123"><a href="#cb5-123" aria-hidden="true" tabindex="-1"></a>        eval_count[<span class="dv">0</span>] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb5-124"><a href="#cb5-124" aria-hidden="true" tabindex="-1"></a>        ll <span class="op">=</span> compute_log_likelihood(theta, data, solver_params)</span>
<span id="cb5-125"><a href="#cb5-125" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose <span class="kw">and</span> eval_count[<span class="dv">0</span>] <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb5-126"><a href="#cb5-126" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Eval </span><span class="sc">{</span>eval_count[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">: theta=</span><span class="sc">{</span>theta<span class="sc">}</span><span class="ss">, LL=</span><span class="sc">{</span>ll<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb5-127"><a href="#cb5-127" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span>ll</span>
<span id="cb5-128"><a href="#cb5-128" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-129"><a href="#cb5-129" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run optimization</span></span>
<span id="cb5-130"><a href="#cb5-130" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> optimize.minimize(</span>
<span id="cb5-131"><a href="#cb5-131" aria-hidden="true" tabindex="-1"></a>        neg_log_lik,</span>
<span id="cb5-132"><a href="#cb5-132" aria-hidden="true" tabindex="-1"></a>        theta_init,</span>
<span id="cb5-133"><a href="#cb5-133" aria-hidden="true" tabindex="-1"></a>        method<span class="op">=</span><span class="st">'Nelder-Mead'</span>,</span>
<span id="cb5-134"><a href="#cb5-134" aria-hidden="true" tabindex="-1"></a>        options<span class="op">=</span>{</span>
<span id="cb5-135"><a href="#cb5-135" aria-hidden="true" tabindex="-1"></a>            <span class="st">'maxiter'</span>: maxiter,</span>
<span id="cb5-136"><a href="#cb5-136" aria-hidden="true" tabindex="-1"></a>            <span class="st">'xatol'</span>: <span class="fl">1e-4</span>,</span>
<span id="cb5-137"><a href="#cb5-137" aria-hidden="true" tabindex="-1"></a>            <span class="st">'fatol'</span>: <span class="fl">1e-4</span>,</span>
<span id="cb5-138"><a href="#cb5-138" aria-hidden="true" tabindex="-1"></a>            <span class="st">'disp'</span>: verbose,</span>
<span id="cb5-139"><a href="#cb5-139" aria-hidden="true" tabindex="-1"></a>            <span class="st">'adaptive'</span>: <span class="va">True</span>,</span>
<span id="cb5-140"><a href="#cb5-140" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb5-141"><a href="#cb5-141" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-142"><a href="#cb5-142" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-143"><a href="#cb5-143" aria-hidden="true" tabindex="-1"></a>    theta_hat <span class="op">=</span> result.x</span>
<span id="cb5-144"><a href="#cb5-144" aria-hidden="true" tabindex="-1"></a>    log_lik_hat <span class="op">=</span> <span class="op">-</span>result.fun</span>
<span id="cb5-145"><a href="#cb5-145" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-146"><a href="#cb5-146" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute standard errors</span></span>
<span id="cb5-147"><a href="#cb5-147" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb5-148"><a href="#cb5-148" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Computing standard errors..."</span>)</span>
<span id="cb5-149"><a href="#cb5-149" aria-hidden="true" tabindex="-1"></a>    std_errors, cov_matrix <span class="op">=</span> compute_standard_errors(</span>
<span id="cb5-150"><a href="#cb5-150" aria-hidden="true" tabindex="-1"></a>        theta_hat, data, solver_params</span>
<span id="cb5-151"><a href="#cb5-151" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-152"><a href="#cb5-152" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-153"><a href="#cb5-153" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> EstimationResult(</span>
<span id="cb5-154"><a href="#cb5-154" aria-hidden="true" tabindex="-1"></a>        theta_hat<span class="op">=</span>theta_hat,</span>
<span id="cb5-155"><a href="#cb5-155" aria-hidden="true" tabindex="-1"></a>        std_errors<span class="op">=</span>std_errors,</span>
<span id="cb5-156"><a href="#cb5-156" aria-hidden="true" tabindex="-1"></a>        cov_matrix<span class="op">=</span>cov_matrix,</span>
<span id="cb5-157"><a href="#cb5-157" aria-hidden="true" tabindex="-1"></a>        log_likelihood<span class="op">=</span>log_lik_hat,</span>
<span id="cb5-158"><a href="#cb5-158" aria-hidden="true" tabindex="-1"></a>        n_iterations<span class="op">=</span>result.nit,</span>
<span id="cb5-159"><a href="#cb5-159" aria-hidden="true" tabindex="-1"></a>        converged<span class="op">=</span>result.success,</span>
<span id="cb5-160"><a href="#cb5-160" aria-hidden="true" tabindex="-1"></a>        optimization_result<span class="op">=</span>result,</span>
<span id="cb5-161"><a href="#cb5-161" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-162"><a href="#cb5-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-163"><a href="#cb5-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-164"><a href="#cb5-164" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_standard_errors(</span>
<span id="cb5-165"><a href="#cb5-165" aria-hidden="true" tabindex="-1"></a>    theta_hat: np.ndarray,</span>
<span id="cb5-166"><a href="#cb5-166" aria-hidden="true" tabindex="-1"></a>    data: PanelData,</span>
<span id="cb5-167"><a href="#cb5-167" aria-hidden="true" tabindex="-1"></a>    solver_params: Dict[<span class="bu">str</span>, Any],</span>
<span id="cb5-168"><a href="#cb5-168" aria-hidden="true" tabindex="-1"></a>    eps: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1e-4</span>,</span>
<span id="cb5-169"><a href="#cb5-169" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> Tuple[np.ndarray, np.ndarray]:</span>
<span id="cb5-170"><a href="#cb5-170" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-171"><a href="#cb5-171" aria-hidden="true" tabindex="-1"></a><span class="co">    Compute standard errors via numerical Hessian.</span></span>
<span id="cb5-172"><a href="#cb5-172" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb5-173"><a href="#cb5-173" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb5-174"><a href="#cb5-174" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb5-175"><a href="#cb5-175" aria-hidden="true" tabindex="-1"></a><span class="co">    theta_hat : np.ndarray</span></span>
<span id="cb5-176"><a href="#cb5-176" aria-hidden="true" tabindex="-1"></a><span class="co">        MLE estimates</span></span>
<span id="cb5-177"><a href="#cb5-177" aria-hidden="true" tabindex="-1"></a><span class="co">    data : PanelData</span></span>
<span id="cb5-178"><a href="#cb5-178" aria-hidden="true" tabindex="-1"></a><span class="co">        Panel data</span></span>
<span id="cb5-179"><a href="#cb5-179" aria-hidden="true" tabindex="-1"></a><span class="co">    solver_params : dict</span></span>
<span id="cb5-180"><a href="#cb5-180" aria-hidden="true" tabindex="-1"></a><span class="co">        Solver hyperparameters</span></span>
<span id="cb5-181"><a href="#cb5-181" aria-hidden="true" tabindex="-1"></a><span class="co">    eps : float</span></span>
<span id="cb5-182"><a href="#cb5-182" aria-hidden="true" tabindex="-1"></a><span class="co">        Step size for finite differences</span></span>
<span id="cb5-183"><a href="#cb5-183" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb5-184"><a href="#cb5-184" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb5-185"><a href="#cb5-185" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb5-186"><a href="#cb5-186" aria-hidden="true" tabindex="-1"></a><span class="co">    std_errors : np.ndarray</span></span>
<span id="cb5-187"><a href="#cb5-187" aria-hidden="true" tabindex="-1"></a><span class="co">        Standard errors for each parameter</span></span>
<span id="cb5-188"><a href="#cb5-188" aria-hidden="true" tabindex="-1"></a><span class="co">    cov_matrix : np.ndarray</span></span>
<span id="cb5-189"><a href="#cb5-189" aria-hidden="true" tabindex="-1"></a><span class="co">        Variance-covariance matrix</span></span>
<span id="cb5-190"><a href="#cb5-190" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-191"><a href="#cb5-191" aria-hidden="true" tabindex="-1"></a>    n_params <span class="op">=</span> <span class="bu">len</span>(theta_hat)</span>
<span id="cb5-192"><a href="#cb5-192" aria-hidden="true" tabindex="-1"></a>    hessian <span class="op">=</span> np.zeros((n_params, n_params))</span>
<span id="cb5-193"><a href="#cb5-193" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-194"><a href="#cb5-194" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_params):</span>
<span id="cb5-195"><a href="#cb5-195" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i, n_params):  <span class="co"># Exploit symmetry</span></span>
<span id="cb5-196"><a href="#cb5-196" aria-hidden="true" tabindex="-1"></a>            theta_pp <span class="op">=</span> theta_hat.copy()</span>
<span id="cb5-197"><a href="#cb5-197" aria-hidden="true" tabindex="-1"></a>            theta_pp[i] <span class="op">+=</span> eps</span>
<span id="cb5-198"><a href="#cb5-198" aria-hidden="true" tabindex="-1"></a>            theta_pp[j] <span class="op">+=</span> eps</span>
<span id="cb5-199"><a href="#cb5-199" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-200"><a href="#cb5-200" aria-hidden="true" tabindex="-1"></a>            theta_pm <span class="op">=</span> theta_hat.copy()</span>
<span id="cb5-201"><a href="#cb5-201" aria-hidden="true" tabindex="-1"></a>            theta_pm[i] <span class="op">+=</span> eps</span>
<span id="cb5-202"><a href="#cb5-202" aria-hidden="true" tabindex="-1"></a>            theta_pm[j] <span class="op">-=</span> eps</span>
<span id="cb5-203"><a href="#cb5-203" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-204"><a href="#cb5-204" aria-hidden="true" tabindex="-1"></a>            theta_mp <span class="op">=</span> theta_hat.copy()</span>
<span id="cb5-205"><a href="#cb5-205" aria-hidden="true" tabindex="-1"></a>            theta_mp[i] <span class="op">-=</span> eps</span>
<span id="cb5-206"><a href="#cb5-206" aria-hidden="true" tabindex="-1"></a>            theta_mp[j] <span class="op">+=</span> eps</span>
<span id="cb5-207"><a href="#cb5-207" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-208"><a href="#cb5-208" aria-hidden="true" tabindex="-1"></a>            theta_mm <span class="op">=</span> theta_hat.copy()</span>
<span id="cb5-209"><a href="#cb5-209" aria-hidden="true" tabindex="-1"></a>            theta_mm[i] <span class="op">-=</span> eps</span>
<span id="cb5-210"><a href="#cb5-210" aria-hidden="true" tabindex="-1"></a>            theta_mm[j] <span class="op">-=</span> eps</span>
<span id="cb5-211"><a href="#cb5-211" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-212"><a href="#cb5-212" aria-hidden="true" tabindex="-1"></a>            f_pp <span class="op">=</span> compute_log_likelihood(theta_pp, data, solver_params)</span>
<span id="cb5-213"><a href="#cb5-213" aria-hidden="true" tabindex="-1"></a>            f_pm <span class="op">=</span> compute_log_likelihood(theta_pm, data, solver_params)</span>
<span id="cb5-214"><a href="#cb5-214" aria-hidden="true" tabindex="-1"></a>            f_mp <span class="op">=</span> compute_log_likelihood(theta_mp, data, solver_params)</span>
<span id="cb5-215"><a href="#cb5-215" aria-hidden="true" tabindex="-1"></a>            f_mm <span class="op">=</span> compute_log_likelihood(theta_mm, data, solver_params)</span>
<span id="cb5-216"><a href="#cb5-216" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-217"><a href="#cb5-217" aria-hidden="true" tabindex="-1"></a>            hessian[i, j] <span class="op">=</span> (f_pp <span class="op">-</span> f_pm <span class="op">-</span> f_mp <span class="op">+</span> f_mm) <span class="op">/</span> (<span class="dv">4</span> <span class="op">*</span> eps <span class="op">*</span> eps)</span>
<span id="cb5-218"><a href="#cb5-218" aria-hidden="true" tabindex="-1"></a>            hessian[j, i] <span class="op">=</span> hessian[i, j]  <span class="co"># Symmetric</span></span>
<span id="cb5-219"><a href="#cb5-219" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-220"><a href="#cb5-220" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Information matrix = -Hessian</span></span>
<span id="cb5-221"><a href="#cb5-221" aria-hidden="true" tabindex="-1"></a>    info_matrix <span class="op">=</span> <span class="op">-</span>hessian</span>
<span id="cb5-222"><a href="#cb5-222" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-223"><a href="#cb5-223" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Covariance = inverse of information matrix</span></span>
<span id="cb5-224"><a href="#cb5-224" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb5-225"><a href="#cb5-225" aria-hidden="true" tabindex="-1"></a>        cov_matrix <span class="op">=</span> np.linalg.inv(info_matrix)</span>
<span id="cb5-226"><a href="#cb5-226" aria-hidden="true" tabindex="-1"></a>        std_errors <span class="op">=</span> np.sqrt(np.diag(cov_matrix))</span>
<span id="cb5-227"><a href="#cb5-227" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> np.linalg.LinAlgError:</span>
<span id="cb5-228"><a href="#cb5-228" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Singular matrix - return NaN</span></span>
<span id="cb5-229"><a href="#cb5-229" aria-hidden="true" tabindex="-1"></a>        cov_matrix <span class="op">=</span> np.full((n_params, n_params), np.nan)</span>
<span id="cb5-230"><a href="#cb5-230" aria-hidden="true" tabindex="-1"></a>        std_errors <span class="op">=</span> np.full(n_params, np.nan)</span>
<span id="cb5-231"><a href="#cb5-231" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-232"><a href="#cb5-232" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> std_errors, cov_matrix</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="step-2-add-tests" class="level3">
<h3 class="anchored" data-anchor-id="step-2-add-tests">Step 2: Add Tests</h3>
<p>File: <code>test/mdp_estimator/test_estimator.py</code></p>
<p>Key tests to implement: 1. <strong>Unit test</strong>: <code>compute_log_likelihood</code> returns correct sign and magnitude 2. <strong>Unit test</strong>: Standard errors are positive and reasonable 3. <strong>Integration test</strong>: Recover true parameters from simulated data 4. <strong>Convergence test</strong>: Optimizer converges for well-specified problems</p>
</section>
<section id="step-3-integration-in-quarto-report" class="level3">
<h3 class="anchored" data-anchor-id="step-3-integration-in-quarto-report">Step 3: Integration in Quarto Report</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># In estimate_mdp.qmd</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load simulated data</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mdp_simulator <span class="im">import</span> simulate_mdp_panel</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mdp_estimator <span class="im">import</span> estimate_mle, EstimationResult</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data at true parameters</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> simulate_mdp_panel(...)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate with perturbed initial values</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>theta_init <span class="op">=</span> (beta <span class="op">*</span> <span class="fl">1.2</span>, gamma <span class="op">*</span> <span class="fl">0.8</span>, delta <span class="op">*</span> <span class="fl">0.95</span>)  <span class="co"># Perturbed</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> estimate_mle(data, theta_init, solver_params)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Display results</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"True:      β=</span><span class="sc">{</span>beta<span class="sc">:.3f}</span><span class="ss">, γ=</span><span class="sc">{</span>gamma<span class="sc">:.3f}</span><span class="ss">, δ=</span><span class="sc">{</span>delta<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated: β=</span><span class="sc">{</span>result<span class="sc">.</span>theta_hat[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, γ=</span><span class="sc">{</span>result<span class="sc">.</span>theta_hat[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">, δ=</span><span class="sc">{</span>result<span class="sc">.</span>theta_hat[<span class="dv">2</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Std Err:   (</span><span class="sc">{</span>result<span class="sc">.</span>std_errors[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>result<span class="sc">.</span>std_errors[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>result<span class="sc">.</span>std_errors[<span class="dv">2</span>]<span class="sc">:.3f}</span><span class="ss">)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>