# AI Practice: Structural Model Estimation

A Python framework for **solving**, **simulating**, and **estimating** structural economic models.

## Supported Models

| Model | Description | Status |
|-------|-------------|--------|
| **MDP** | Dynamic Discrete Choice (Markov Decision Process) | âœ… Complete |
| **OPM** | Oligopoly Pricing Model | ğŸš§ Coming Soon |

---

## MDP: Dynamic Discrete Choice Models

A complete implementation for structural estimation of MDPs:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MDP Solver    â”‚â”€â”€â”€â”€â–¶â”‚   MDP Simulator  â”‚â”€â”€â”€â”€â–¶â”‚   MDP Estimator  â”‚
â”‚  (Neural Net    â”‚     â”‚  (Monte Carlo    â”‚     â”‚  (Two-Step       â”‚
â”‚   Value Iter.)  â”‚     â”‚   Panel Data)    â”‚     â”‚   NFXP-MLE)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚                        â”‚
        â–¼                        â–¼                        â–¼
   Value Functions          Panel Data             Recovered Î¸Ì‚
   (vâ‚€, vâ‚ networks)    (100Ã—100 obs)         (Î²Ì‚, Î³Ì‚, Î´ calibrated)
```

### The Model

Agents make binary choices (invest or not) to maximize lifetime utility:

- **State transition** (deterministic): $s_{t+1} = (1 - \gamma)s_t + a_t$
- **Flow utility**: $u(s, a) = \beta \log(1 + s) - a$
- **Type-I Extreme Value shocks**: Leading to logit choice probabilities
- **Infinite horizon**: With discount factor $\delta$

---

## Key Results

### Stage 1: Solver
- Converges in ~3,000 iterations with RMSE < 0.01
- Monotonic neural networks enforce economic structure (value increasing in state)
- Comparative statics show sensible responses to Î² and Î³

### Stage 2: Simulator
- Generates 100 agents Ã— 100 periods = 10,000 observations
- All validation checks pass:
  - âœ“ Choice probabilities match theoretical logit
  - âœ“ State transitions follow $s' = (1-\gamma)s + a$
  - âœ“ State distribution converges to stationarity

### Stage 3: Estimator
Successfully recovers structural parameters using two-step estimation:

| Parameter | True | Estimated | Method | Recovery |
|-----------|------|-----------|--------|----------|
| **Î²** (reward) | 1.0 | ~1.03 | MLE (1D grid) | âœ“ Within 2 SE |
| **Î³** (decay) | 0.1 | 0.1 | OLS | âœ“ Exact (RÂ²=1.0) |
| **Î´** (discount) | 0.95 | 0.95 | Calibrated | â€” |

**Key insight**: Joint 3-parameter estimation suffers from weak identification (flat likelihood surface). The two-step approach exploits model structure: Î³ is identified from transitions alone, Î´ is typically calibrated, leaving only Î² for MLE.

---

## Project Structure

```
AI_Practice/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ mdp/                      # MDP model
â”‚   â”‚   â”œâ”€â”€ solver/               # Neural network value iteration
â”‚   â”‚   â”œâ”€â”€ simulator/            # Monte Carlo simulation
â”‚   â”‚   â””â”€â”€ estimator/            # Two-step structural estimation
â”‚   â””â”€â”€ opm/                      # OPM model (placeholder)
â”‚       â”œâ”€â”€ solver/
â”‚       â”œâ”€â”€ simulator/
â”‚       â””â”€â”€ estimator/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ mdp/
â”‚   â”‚   â”œâ”€â”€ config/               # Centralized parameters (Î²=1.0, Î³=0.1, Î´=0.95)
â”‚   â”‚   â”œâ”€â”€ solve/                # Solver report with comparative statics
â”‚   â”‚   â”œâ”€â”€ simulate/             # Simulation report with diagnostics
â”‚   â”‚   â””â”€â”€ estimate/             # Estimation report with identification analysis
â”‚   â”œâ”€â”€ opm/                      # OPM scripts (placeholder)
â”‚   â””â”€â”€ utils/                    # Shared plotting utilities
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ mdp/
â”‚   â”‚   â”œâ”€â”€ solve/                # Trained networks (v0_net.pt, v1_net.pt)
â”‚   â”‚   â”œâ”€â”€ simulate/             # Panel data (states.npy, actions.npy)
â”‚   â”‚   â””â”€â”€ estimate/
â”‚   â””â”€â”€ opm/                      # OPM output (placeholder)
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ mdp/                      # MDP tests
â”‚   â”‚   â”œâ”€â”€ solver/
â”‚   â”‚   â”œâ”€â”€ simulator/
â”‚   â”‚   â””â”€â”€ estimator/
â”‚   â””â”€â”€ opm/                      # OPM tests (placeholder)
â””â”€â”€ docs/
    â”œâ”€â”€ mdp/                      # MDP development logs
    â””â”€â”€ opm/                      # OPM documentation (placeholder)
```

---

## Pipeline Details

### 1. MDP Solver (`src/mdp/solver`)

Solves the Bellman equation using neural network approximation with **target networks** for stability:

```python
from mdp.solver import solve_value_function

v0_net, v1_net, losses, n_iter = solve_value_function(
    beta=1.0, gamma=0.1, delta=0.95,
    s_min=0.0, s_max=10.0,
    hidden_sizes=[16],  # Single hidden layer
)
```

**Key features:**
- **Monotonic networks**: Non-negative weights via softplus ensure $v(s,a)$ increasing in $s$
- **Target networks**: Frozen copies updated periodically for stable Bellman targets
- **Tanh activation**: Bounded outputs prevent explosive growth
- **Comparative statics**: Reports analyze effects of varying Î² (0â†’2) and Î³ (0â†’0.1)

### 2. MDP Simulator (`src/mdp/simulator`)

Generates synthetic panel data using solved value functions:

```python
from mdp.simulator import simulate_mdp_panel

panel = simulate_mdp_panel(
    v0_net, v1_net,
    n_agents=100, n_periods=100,
    s_init=np.random.uniform(0, 10, 100),
    beta=1.0, gamma=0.1,
)
```

**Validation checks:**
- Choice probability RMSE < 0.05
- Calibration RMSE < 0.03
- State convergence to stationarity
- Exact transition verification
- Reward consistency

### 3. MDP Estimator (`src/mdp/estimator`)

Recovers structural parameters using **two-step estimation**:

```python
from mdp.estimator import estimate_two_step

result = estimate_two_step(
    data=panel,
    delta_calibrated=0.95,
    solver_params=solver_params,
    beta_bounds=(0.5, 1.5),
    n_points=20,
)
# result.gamma_hat: 0.1 (exact from OLS)
# result.beta_hat: ~1.03 (within 2 SE)
```

**Two-step approach:**
1. **Step 1**: Estimate Î³ from transitions via OLS (exact, RÂ²=1.0)
2. **Step 2**: Estimate Î² via 1D grid search (Î´ calibrated, ~20 evaluations)

This decomposition addresses weak identification between Î² and Î´.

---

## Configuration

All parameters are centralized in `scripts/mdp/config/config.py`:

```python
# Model parameters
beta = 1.0      # Reward coefficient
gamma = 0.1     # State decay rate  
delta = 0.95    # Discount factor
s_min = 0.0     # State lower bound
s_max = 10.0    # State upper bound

# Network architecture
hidden_sizes = [16]        # Single hidden layer
learning_rate = 0.1        # Higher LR works with target networks
batch_size = 256
tolerance = 0.01           # Convergence tolerance (RMSE)
max_iterations = 20000
target_update_freq = 10    # Target network sync frequency
```

---

## Running Tests

```bash
# All tests
uv run pytest test/ -v

# Fast unit tests only
uv run pytest test/ -v -m "not slow"

# Slow integration tests
uv run pytest test/ -v -m slow
```

---

## Technical Notes

### Why Two-Step Estimation?

Joint estimation of (Î², Î³, Î´) reveals **weak identification**:
- Likelihood at true Î¸: -6875
- Likelihood at estimated Î¸: -6874
- Difference: <2 log-units (essentially indistinguishable)

The two-step approach exploits model structure:
- **Î³ enters only transitions**: $s' = (1-\gamma)s + a$ â†’ OLS gives exact recovery
- **Î´ is typically calibrated**: Standard practice in structural IO
- **Î² becomes 1D**: Grid search is robust to flat surfaces

### NFXP Structure

Each likelihood evaluation requires solving the DP (inner loop):
```
FOR each candidate Î²:
    1. Solve DP: v0, v1 = solve_value_function(Î², Î³_ols, Î´_calib)
    2. Compute choice probabilities from (v0, v1)  
    3. Evaluate log-likelihood
RETURN Î² with highest likelihood
```

**Optimization**: Warm-starting from pre-trained networks speeds convergence.

---

## OPM: Oligopoly Pricing Model

ğŸš§ **Coming Soon**

The OPM module will implement structural estimation for oligopoly pricing models following the same pipeline: **Solver â†’ Simulator â†’ Estimator**.

---

## License

MIT License
